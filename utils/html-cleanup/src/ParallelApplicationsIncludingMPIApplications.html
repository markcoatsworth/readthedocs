<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Parallel Applications (Including MPI Applications)</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<!-- 3,sec-filename,next,info,NoFonts,fonts,html --> 
<meta name="src" content="ref.tex"> 
<link rel="stylesheet" type="text/css" href="ref.css"> 
</head><body 
>
   <span style="font-size: 200%;"><a 
href="JavaApplications.html" >&#x21D0;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="JavaApplications.html#tailJavaApplications.html" >&#x2199;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="#tailParallelApplicationsIncludingMPIApplications.html">&#x2193;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="UsersManual.html#ParallelApplicationsIncludingMPIApplications.html" >&#x21D1;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="DAGManApplications.html" >&#x21D2;</a></span>&nbsp;<a href="contentsname.html">Contents</a>&nbsp;<a href="indexname.html">Index</a><h3 class="sectionHead"><span class="titlemark">2.9   </span> <a 
 id="x21-700002.9"></a>Parallel Applications (Including MPI Applications)</h3>
   <div class="sectionTOCS">
   &#x00A0;&#x00A0;<span class="subsectionToc" >2.9.1 <a 
href="#x21-710002.9.1">How Parallel Jobs Run</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >2.9.2 <a 
href="#x21-720002.9.2">Parallel Jobs and the Dedicated Scheduler</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >2.9.3 <a 
href="#x21-730002.9.3">Submission Examples</a></span>
<br />   &#x00A0;&#x00A0;<span class="subsectionToc" >2.9.4 <a 
href="#x21-740002.9.4">MPI Applications Within HTCondor&#8217;s Vanilla Universe</a></span>
   </div>
<a 
 id="dx21-70001"></a>
<a 
 id="dx21-70002"></a>
<!--l. 7--><p class="indent" >   HTCondor&#8217;s parallel universe supports jobs that span multiple machines, where the multiple processes within a
job must be running concurrently on these multiple machines, perhaps communicating with each other. The parallel
universe provides machine scheduling, but does not enforce a particular programming paradigm for the underlying
applications. Thus, parallel universe jobs may run under various MPI implementations as well as under other
programming environments.
<!--l. 16--><p class="indent" >   The parallel universe supersedes the mpi universe. The mpi universe eventually will be removed from
HTCondor.
<!--l. 20--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.9.1   </span> <a 
 id="x21-710002.9.1"></a>How Parallel Jobs Run</h4>
<!--l. 23--><p class="noindent" >Parallel universe jobs are submitted from the machine running the dedicated scheduler. The dedicated scheduler
matches and claims a fixed number of machines (slots) for the parallel universe job, and when a sufficient number of
machines are claimed, the parallel job is started on each claimed slot.
<!--l. 30--><p class="indent" >   Each invocation of <span class="textit">condor_submit</span> assigns a single <span class="texttt">ClusterId</span> for what is considered the single parallel job
submitted. The <span class="textbf">machine_count</span><a 
 id="dx21-71001"></a> submit command identifies how many machines (slots) are to be allocated. Each
instance of the <span class="textbf">queue</span><a 
 id="dx21-71002"></a> submit command acquires and claims the number of slots specified by <span class="textbf">machine_count</span>.
Each of these slots shares a common job ClassAd and will have the same <span class="texttt">ProcId</span> job ClassAd attribute
value.
                                                                                         

                                                                                         
<!--l. 39--><p class="indent" >   Once the correct number of machines are claimed, the <span class="textbf">executable</span><a 
 id="dx21-71003"></a> is started at more or less the same time on all
machines. If desired, a monotonically increasing integer value that starts at 0 may be provided to each of these
machines. The macro <span class="texttt">$(Node)</span> is similar to the MPI <span class="emph">rank</span> construct. This macro may be used within the submit
description file in either the <span class="textbf">arguments</span><a 
 id="dx21-71004"></a> or <span class="textbf">environment</span><a 
 id="dx21-71005"></a> command. Thus, as the executable runs, it may discover
its own <span class="texttt">$(Node)</span> value.
<!--l. 51--><p class="indent" >   Node 0 has special meaning and consequences for the parallel job. The completion of a parallel job is implied and
taken to be when the Node 0 executable exits. All other nodes that are part of the parallel job and
that have not yet exited on their own are killed. This default behavior may be altered by placing the
line
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-129">
<span 
class="ectt-1000">+ParallelShutdownPolicy</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;"WAIT_FOR_ALL"</span>
</div>
<!--l. 59--><p class="nopar" > in the submit description file. It causes HTCondor to wait until every node in the parallel job has completed to
consider the job finished.
<!--l. 65--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.9.2   </span> <a 
 id="x21-720002.9.2"></a>Parallel Jobs and the Dedicated Scheduler</h4>
<!--l. 68--><p class="noindent" >To run parallel universe jobs, HTCondor must be configured such that <a 
 id="dx21-72001"></a>machines running parallel jobs are <span class="emph">dedicated</span>.
Note that dedicated has a very specific meaning in HTCondor: while dedicated machines can run serial jobs,
they prefer to run parallel jobs, and dedicated machines never preempt a parallel job once it starts
running.
<!--l. 76--><p class="indent" >   A machine becomes a dedicated machine when an administrator configures it to accept parallel jobs from one
specific dedicated scheduler. Note the difference between parallel and serial jobs. While any scheduler in a pool can
send serial jobs to any machine, only the designated dedicated scheduler may send parallel universe jobs to a
dedicated machine. Dedicated machines must be specially configured. See section&#x00A0;<a 
href="SettingUpforSpecialEnvironments.html#x42-3650003.14.9">3.14.9<!--tex4ht:ref: sec:Config-Dedicated-Jobs --></a> for a description of the
necessary configuration, as well as examples. Usually, a single dedicated scheduler is configured for a pool which can
run parallel universe jobs, and this <span class="textit">condor_schedd</span> daemon becomes the single machine from which parallel universe
jobs are submitted.
<!--l. 90--><p class="indent" >   The following command line will list the execute machines in the local pool which have been configured to use a
dedicated scheduler, also printing the name of that dedicated scheduler. In order to run parallel jobs, this name
will be defined to be the string <span class="texttt">"DedicatedScheduler@"</span>, prepended to the name of the scheduler
host.
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-130">
<span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;condor_status</span><span 
class="ectt-0800">&#x00A0;-const</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="tctt-0800">'</span><span 
class="ectt-0800">!isUndefined(DedicatedScheduler)</span><span 
class="tctt-0800">'</span><span 
class="ectt-0800">&#x00A0;\</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">-format</span><span 
class="ectt-0800">&#x00A0;"%s\t"</span><span 
class="ectt-0800">&#x00A0;Machine</span><span 
class="ectt-0800">&#x00A0;-format</span><span 
class="ectt-0800">&#x00A0;"%s\n"</span><span 
class="ectt-0800">&#x00A0;DedicatedScheduler</span>
<span 
class="ectt-0800">&#x00A0;</span><br />
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">execute1.example.com DedicatedScheduler@submit.example.com</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">execute2.example.com DedicatedScheduler@submit.example.com</span>
<span 
class="ectt-0800">&#x00A0;</span><br />
</div>
<!--l. 105--><p class="nopar" >
<!--l. 108--><p class="indent" >   If this command emits no lines of output, then then pool is not correctly configured to run parallel jobs. Make
sure that the name of the scheduler is correct. The string after the <span class="texttt">@</span> sign should match the name of the
<span class="textit">condor_schedd</span> daemon, as returned by the command
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-131">
<span 
class="ectt-1000">&#x00A0;</span><span 
class="ectt-1000">&#x00A0;condor_status</span><span 
class="ectt-1000">&#x00A0;-schedd</span>
</div>
<!--l. 116--><p class="nopar" >
<!--l. 119--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.9.3   </span> <a 
 id="x21-730002.9.3"></a>Submission Examples</h4>
     <dl class="description"><dt class="description">
Simplest Example </dt><dd 
class="description"></dd></dl>
<!--l. 126--><p class="noindent" >Here is a submit description file for a parallel universe job example that is as simple as possible:
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-132">
<span 
class="ectt-1000">#############################################</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">##</span><span 
class="ectt-1000">&#x00A0;</span><span 
class="ectt-1000">&#x00A0;submit</span><span 
class="ectt-1000">&#x00A0;description</span><span 
class="ectt-1000">&#x00A0;file</span><span 
class="ectt-1000">&#x00A0;for</span><span 
class="ectt-1000">&#x00A0;a</span><span 
class="ectt-1000">&#x00A0;parallel</span><span 
class="ectt-1000">&#x00A0;universe</span><span 
class="ectt-1000">&#x00A0;job</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">#############################################</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">universe</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;parallel</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">executable</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;/bin/sleep</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">arguments</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;30</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">machine_count</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;8</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">log</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;log</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">should_transfer_files</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;IF_NEEDED</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">when_to_transfer_output</span><span 
class="ectt-1000">&#x00A0;=</span><span 
class="ectt-1000">&#x00A0;ON_EXIT</span>
<span 
class="ectt-1000">&#x00A0;</span><br /><span 
class="ectt-1000">queue</span>
</div>
<!--l. 141--><p class="nopar" >
<!--l. 143--><p class="indent" >   This job specifies the <span class="textbf">universe</span> as <span class="textbf">parallel</span>, letting HTCondor know that dedicated resources are required. The
<span class="textbf">machine_count</span><a 
 id="dx21-73001"></a> command identifies that eight machines are required for this job.
<!--l. 148--><p class="indent" >   Because no <span class="textbf">requirements</span><a 
 id="dx21-73002"></a> are specified, the dedicated scheduler claims eight machines with the same
architecture and operating system as the submit machine. When all the machines are ready, it invokes the
<span class="textit">/bin/sleep</span> command, with a command line argument of 30 on each of the eight machines more or less
simultaneously. Job events are written to the log specified in the <span class="textbf">log</span><a 
 id="dx21-73003"></a> command.
<!--l. 156--><p class="indent" >   The file transfer mechanism is enabled for this parallel job, such that if any of the eight claimed execute
machines does not share a file system with the submit machine, HTCondor will correctly transfer the
executable. This <span class="textit">/bin/sleep</span> example implies that the submit machine is running a Unix operating system,
and the default assumption for submission from a Unix machine would be that there is a shared file
system.
     <dl class="description"><dt class="description">
Example with Operating System Requirements </dt><dd 
class="description"></dd></dl>
<!--l. 169--><p class="indent" >   Assume that the pool contains Linux machines installed with either a RedHat or an Ubuntu operating
system. If the job should run only on RedHat platforms, the requirements expression may specify
this:
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-133">
<span 
class="ectt-0800">#############################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span><span 
class="ectt-0800">&#x00A0;for</span><span 
class="ectt-0800">&#x00A0;a</span><span 
class="ectt-0800">&#x00A0;parallel</span><span 
class="ectt-0800">&#x00A0;program</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;targeting</span><span 
class="ectt-0800">&#x00A0;RedHat</span><span 
class="ectt-0800">&#x00A0;machines</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#############################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;parallel</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;/bin/sleep</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">arguments</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;30</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;8</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">log</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;log</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;IF_NEEDED</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;ON_EXIT</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">requirements</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;(OpSysName</span><span 
class="ectt-0800">&#x00A0;==</span><span 
class="ectt-0800">&#x00A0;"RedHat")</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 189--><p class="nopar" >
<!--l. 192--><p class="indent" >   The machine selection may be further narrowed, instead using the <span class="texttt">OpSysAndVer</span> attribute.
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-134">
<span 
class="ectt-0800">#############################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span><span 
class="ectt-0800">&#x00A0;for</span><span 
class="ectt-0800">&#x00A0;a</span><span 
class="ectt-0800">&#x00A0;parallel</span><span 
class="ectt-0800">&#x00A0;program</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;targeting</span><span 
class="ectt-0800">&#x00A0;RedHat</span><span 
class="ectt-0800">&#x00A0;6</span><span 
class="ectt-0800">&#x00A0;machines</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#############################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;parallel</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;/bin/sleep</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">arguments</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;30</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;8</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">log</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;log</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;IF_NEEDED</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;ON_EXIT</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">requirements</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;(OpSysAndVer</span><span 
class="ectt-0800">&#x00A0;==</span><span 
class="ectt-0800">&#x00A0;"RedHat6")</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 210--><p class="nopar" >
     <dl class="description"><dt class="description">
Using the <span class="texttt">$(Node)</span> Macro </dt><dd 
class="description"></dd></dl>
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-135">
<span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span><span 
class="ectt-0800">&#x00A0;for</span><span 
class="ectt-0800">&#x00A0;a</span><span 
class="ectt-0800">&#x00A0;parallel</span><span 
class="ectt-0800">&#x00A0;program</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;showing</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;$(Node)</span><span 
class="ectt-0800">&#x00A0;macro</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;parallel</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;/bin/cat</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">log</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;logfile</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">input</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;infile.$(Node)</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;outfile.$(Node)</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">error</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;errfile.$(Node)</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;4</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;IF_NEEDED</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;ON_EXIT</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 233--><p class="nopar" >
<!--l. 236--><p class="indent" >   The <span class="texttt">$(Node)</span> macro is expanded to values of 0-3 as the job instances are about to be started. This assigns unique
names to the input and output files to be transferred or accessed from the shared file system. The <span class="texttt">$(Node)</span> value is
fixed for the entire length of the job.
     <dl class="description"><dt class="description">
Differing Requirements for the Machines </dt><dd 
class="description"></dd></dl>
<!--l. 246--><p class="indent" >   Sometimes one machine&#8217;s part in a parallel job will have specialized needs. These can be handled with a
<span class="textbf">Requirements</span><a 
 id="dx21-73004"></a> submit command that also specifies the number of needed machines.
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-136">
<span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;Example</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;with</span><span 
class="ectt-0800">&#x00A0;4</span><span 
class="ectt-0800">&#x00A0;total</span><span 
class="ectt-0800">&#x00A0;machines</span><span 
class="ectt-0800">&#x00A0;and</span><span 
class="ectt-0800">&#x00A0;differing</span><span 
class="ectt-0800">&#x00A0;requirements</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;parallel</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;special.exe</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;1</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">requirements</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;(</span><span 
class="ectt-0800">&#x00A0;machine</span><span 
class="ectt-0800">&#x00A0;==</span><span 
class="ectt-0800">&#x00A0;"machine1@example.com")</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
<span 
class="ectt-0800">&#x00A0;</span><br />
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;3</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">requirements</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;(</span><span 
class="ectt-0800">&#x00A0;machine</span><span 
class="ectt-0800">&#x00A0;=!=</span><span 
class="ectt-0800">&#x00A0;"machine1@example.com")</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 265--><p class="nopar" >
<!--l. 268--><p class="indent" >   The dedicated scheduler acquires and claims four machines. All four share the same value of <span class="texttt">ClusterId</span>, as this
value is associated with this single parallel job. The existence of a second <span class="textbf">queue</span><a 
 id="dx21-73005"></a> command causes a total of two
<span class="texttt">ProcId</span> values to be assigned for this parallel job. The <span class="texttt">ProcId</span> values are assigned based on ordering within the
submit description file. Value 0 will be assigned for the single executable that must be executed on
machine1@example.com, and the value 1 will be assigned for the other three that must be executed
elsewhere.
     <dl class="description"><dt class="description">
Requesting multiple cores per slot </dt><dd 
class="description"></dd></dl>
<!--l. 284--><p class="indent" >   If the parallel program has a structure that benefits from running on multiple cores within the same slot,
multi-core slots may be specified.
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-137">
<span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span><span 
class="ectt-0800">&#x00A0;for</span><span 
class="ectt-0800">&#x00A0;a</span><span 
class="ectt-0800">&#x00A0;parallel</span><span 
class="ectt-0800">&#x00A0;program</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;that</span><span 
class="ectt-0800">&#x00A0;needs</span><span 
class="ectt-0800">&#x00A0;8-core</span><span 
class="ectt-0800">&#x00A0;slots</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;parallel</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;foo.sh</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">log</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;logfile</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">input</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;infile.$(Node)</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;outfile.$(Node)</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">error</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;errfile.$(Node)</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;2</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">request_cpus</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;8</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;IF_NEEDED</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;ON_EXIT</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 305--><p class="nopar" >
<!--l. 308--><p class="indent" >   This parallel job causes the scheduler to match and claim two machines, where each of the machines (slots) has
eight cores. The parallel job is assigned a single <span class="texttt">ClusterId</span> and a single <span class="texttt">ProcId</span>, meaning that there is a single job
ClassAd for this job.
<!--l. 314--><p class="indent" >   The executable, <span class="texttt">foo.sh</span>, is started at the same time on a single core within each of the two machines (slots). It is
presumed that the executable will take care of invoking processes that are to run on the other seven CPUs (cores)
associated with the slot.
<!--l. 320--><p class="indent" >   Potentially fewer machines are impacted with this specification, as compared with the request that
contains
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-138">
<span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;16</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">request_cpus</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;1</span>
</div>
<!--l. 326--><p class="nopar" > The interaction of the eight cores within the single slot may be advantageous with respect to communication delay
or memory access. But, 8-core slots must be available within the pool.
     <dl class="description"><dt class="description">
MPI Applications </dt><dd 
class="description"></dd></dl>
<a 
 id="dx21-73006"></a>
<a 
 id="dx21-73007"></a>
<!--l. 340--><p class="indent" >   MPI applications use a single executable, invoked on one or more machines (slots), executing in parallel. The
various implementations of MPI such as Open MPI and MPICH require further framework. HTCondor supports this
necessary framework through a user-modified script. This implementation-dependent script becomes the
HTCondor executable. The script sets up the framework, and then it invokes the MPI application&#8217;s
executable.
<!--l. 350--><p class="indent" >   The scripts are located in the <span class="texttt"><span class="texttt">$(RELEASE_DIR)</span>/etc/examples</span> directory. The script for the Open MPI
implementation is <span class="texttt">openmpiscript</span>. The scripts for MPICH implementations are <span class="texttt">mp1script</span> and <span class="texttt">mp2script</span>. An
MPICH3 script is not available at this time. These scripts rely on running <span class="textit">ssh</span> for communication between the nodes
of the MPI application. The <span class="textit">ssh</span> daemon on Unix platforms restricts connections to the approved shells listed in the
<span class="texttt">/etc/shells</span> file.
<!--l. 360--><p class="indent" >   Here is a sample submit description file for an MPICH MPI application:
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-139">
<span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;Example</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;for</span><span 
class="ectt-0800">&#x00A0;MPICH</span><span 
class="ectt-0800">&#x00A0;1</span><span 
class="ectt-0800">&#x00A0;MPI</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;works</span><span 
class="ectt-0800">&#x00A0;with</span><span 
class="ectt-0800">&#x00A0;MPICH</span><span 
class="ectt-0800">&#x00A0;1.2.4,</span><span 
class="ectt-0800">&#x00A0;1.2.5</span><span 
class="ectt-0800">&#x00A0;and</span><span 
class="ectt-0800">&#x00A0;1.2.6</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;parallel</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;mp1script</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">arguments</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;my_mpich_linked_executable</span><span 
class="ectt-0800">&#x00A0;arg1</span><span 
class="ectt-0800">&#x00A0;arg2</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;4</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;yes</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;on_exit</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">transfer_input_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;my_mpich_linked_executable</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 377--><p class="nopar" >
<!--l. 380--><p class="indent" >   The <span class="textbf">executable</span><a 
 id="dx21-73008"></a> is the <span class="texttt">mp1script</span> script that will have been modified for this MPI application. This
script is invoked on each slot or core. The script, in turn, is expected to invoke the MPI application&#8217;s
executable. To know the MPI application&#8217;s executable, it is the first in the list of <span class="textbf">arguments</span><a 
 id="dx21-73009"></a>. And,
since HTCondor must transfer this executable to the machine where it will run, it is listed with the
<span class="textbf">transfer_input_files</span><a 
 id="dx21-73010"></a> command, and the file transfer mechanism is enabled with the <span class="textbf">should_transfer_files</span><a 
 id="dx21-73011"></a>
command.
<!--l. 392--><p class="indent" >   Here is the equivalent sample submit description file, but for an Open MPI application:
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-140">
<span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;Example</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;for</span><span 
class="ectt-0800">&#x00A0;Open</span><span 
class="ectt-0800">&#x00A0;MPI</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">######################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;parallel</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;openmpiscript</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">arguments</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;my_openmpi_linked_executable</span><span 
class="ectt-0800">&#x00A0;arg1</span><span 
class="ectt-0800">&#x00A0;arg2</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">machine_count</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;4</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;yes</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;on_exit</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">transfer_input_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;my_openmpi_linked_executable</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 409--><p class="nopar" >
<!--l. 412--><p class="indent" >   Most MPI implementations require two system-wide prerequisites. The first prerequisite is the ability to run a
command on a remote machine without being prompted for a password. <span class="textit">ssh</span> is commonly used. The second
prerequisite is an ASCII file containing the list of machines that may utilize <span class="textit">ssh</span>. These common prerequisites are
implemented in a further script called <span class="texttt">sshd.sh</span>. <span class="texttt">sshd.sh</span> generates ssh keys to enable password-less
remote execution and starts an <span class="textit">sshd</span> daemon. Use of the <span class="textit">sshd.sh</span> script requires the definition of two
HTCondor configuration variables. Configuration variable <span class="texttt">CONDOR_SSHD</span> <a 
 id="dx21-73012"></a><a 
 id="dx21-73013"></a> is an absolute path to an
implementation of <span class="textit">sshd</span>. <span class="textit">sshd.sh</span> has been tested with <span class="textit">openssh</span> version 3.9, but should work with more
recent versions. Configuration variable <span class="texttt">CONDOR_SSH_KEYGEN</span> <a 
 id="dx21-73014"></a><a 
 id="dx21-73015"></a> points to the corresponding <span class="textit">ssh-keygen</span>
executable.
<!--l. 433--><p class="indent" >   <span class="textit">mp1script</span> and <span class="textit">mp2script</span> require the <span class="texttt">PATH</span> to the MPICH installation to be set. The variable <span class="texttt">MPDIR</span> may
be modified in the scripts to indicate its proper value. This directory contains the MPICH <span class="textit">mpirun</span>
executable.
<!--l. 437--><p class="indent" >   <span class="textit">openmpiscript</span> also requires the <span class="texttt">PATH</span> to the Open MPI installation. Either the variable <span class="texttt">MPDIR</span> can be
set manually in the script, or the administrator can define <span class="texttt">MPDIR</span> using the configuration variable
<span class="texttt">OPENMPI_INSTALL_PATH</span> <a 
 id="dx21-73016"></a><a 
 id="dx21-73017"></a>. When using Open MPI on a multi-machine HTCondor cluster, the administrator may also
want to consider tweaking the <span class="texttt">OPENMPI_EXCLUDE_NETWORK_INTERFACES</span> <a 
 id="dx21-73018"></a><a 
 id="dx21-73019"></a> configuration variable as well as set
<span class="texttt">MOUNT_UNDER_SCRATCH</span> = <span class="texttt">/tmp</span>.
<a 
 id="dx21-73020"></a>
<!--l. 456--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.9.4   </span> <a 
 id="x21-740002.9.4"></a>MPI Applications Within HTCondor&#8217;s Vanilla Universe</h4>
<!--l. 459--><p class="noindent" >The vanilla universe may be preferred over the parallel universe for certain parallel applications such as MPI ones.
These applications are ones in which the allocated cores need to be within a single slot. The <span class="textbf">request_cpus</span><a 
 id="dx21-74001"></a>
command causes a claimed slot to have the required number of CPUs (cores).
                                                                                         

                                                                                         
<!--l. 466--><p class="indent" >   There are two ways to ensure that the MPI job can run on any machine that it lands on:
     <ol  class="enumerate1" >
     <li 
  class="enumerate" id="x21-74003x1">Statically build an MPI library and statically compile the MPI code.
     </li>
     <li 
  class="enumerate" id="x21-74005x2">Use CDE to create a directory tree that contains all of the libraries needed to execute the MPI code.</li></ol>
<!--l. 474--><p class="indent" >   For Linux machines, our experience recommends using CDE, as building static MPI libraries can be difficult.
CDE can be found at <a 
href="http://www.pgbovine.net/cde.html" >http://www.pgbovine.net/cde.html</a>.
<!--l. 478--><p class="indent" >   Here is a submit description file example assuming that MPI is installed on all machines on which the
MPI job may run, or that the code was built using static libraries and a static version of <span class="texttt">mpirun</span> is
available.
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-141">
<span 
class="ectt-0800">############################################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span><span 
class="ectt-0800">&#x00A0;for</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;static</span><span 
class="ectt-0800">&#x00A0;build</span><span 
class="ectt-0800">&#x00A0;of</span><span 
class="ectt-0800">&#x00A0;MPI</span><span 
class="ectt-0800">&#x00A0;under</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;vanilla</span><span 
class="ectt-0800">&#x00A0;universe</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">############################################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;vanilla</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;/path/to/mpirun</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">request_cpus</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;2</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">arguments</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;-np</span><span 
class="ectt-0800">&#x00A0;2</span><span 
class="ectt-0800">&#x00A0;my_mpi_linked_executable</span><span 
class="ectt-0800">&#x00A0;arg1</span><span 
class="ectt-0800">&#x00A0;arg2</span><span 
class="ectt-0800">&#x00A0;arg3</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;yes</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;on_exit</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">transfer_input_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;my_mpi_linked_executable</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 498--><p class="nopar" >
<!--l. 501--><p class="indent" >   If CDE is to be used, then CDE needs to be run first to create the directory tree. On the host machine which has
the original program, the command
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-142">
<span 
class="ectt-0800">prompt-&#x003E;</span><span 
class="ectt-0800">&#x00A0;cde</span><span 
class="ectt-0800">&#x00A0;mpirun</span><span 
class="ectt-0800">&#x00A0;-n</span><span 
class="ectt-0800">&#x00A0;2</span><span 
class="ectt-0800">&#x00A0;my_mpi_linked_executable</span>
</div>
<!--l. 508--><p class="nopar" >
<!--l. 511--><p class="indent" >   creates a directory tree that will contain all libraries needed for the program. By creating a tarball
of this directory, the user can package up the executable itself, any files needed for the executable,
and all necessary libraries. The following example assumes that the user has created a tarball called
<span class="texttt">cde_my_mpi_linked_executable.tar</span> which contains the directory tree created by CDE.
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-143">
<span 
class="ectt-0800">############################################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;submit</span><span 
class="ectt-0800">&#x00A0;description</span><span 
class="ectt-0800">&#x00A0;file</span><span 
class="ectt-0800">&#x00A0;for</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">##</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;</span><span 
class="ectt-0800">&#x00A0;MPI</span><span 
class="ectt-0800">&#x00A0;under</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;vanilla</span><span 
class="ectt-0800">&#x00A0;universe;</span><span 
class="ectt-0800">&#x00A0;CDE</span><span 
class="ectt-0800">&#x00A0;used</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">############################################################</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">universe</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;vanilla</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">executable</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;cde_script.sh</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">request_cpus</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;2</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">should_transfer_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;yes</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">when_to_transfer_output</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;on_exit</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">transfer_input_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;cde_my_mpi_linked_executable.tar</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">transfer_output_files</span><span 
class="ectt-0800">&#x00A0;=</span><span 
class="ectt-0800">&#x00A0;cde-package/cde-root/path/to/original/directory</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">queue</span>
</div>
<!--l. 535--><p class="nopar" >
<!--l. 538--><p class="indent" >   The executable is now a specialized shell script tailored to this job. In this example, <span class="textit">cde_script.sh</span>
contains:
                                                                                         

                                                                                         
   <div class="verbatim" id="verbatim-144">
<span 
class="ectt-0800">#!/bin/sh</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#</span><span 
class="ectt-0800">&#x00A0;Untar</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;CDE</span><span 
class="ectt-0800">&#x00A0;package</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">tar</span><span 
class="ectt-0800">&#x00A0;xpf</span><span 
class="ectt-0800">&#x00A0;cde_my_mpi_linked_executable.tar</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#</span><span 
class="ectt-0800">&#x00A0;cd</span><span 
class="ectt-0800">&#x00A0;to</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;subdirectory</span><span 
class="ectt-0800">&#x00A0;where</span><span 
class="ectt-0800">&#x00A0;I</span><span 
class="ectt-0800">&#x00A0;need</span><span 
class="ectt-0800">&#x00A0;to</span><span 
class="ectt-0800">&#x00A0;run</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">cd</span><span 
class="ectt-0800">&#x00A0;cde-package/cde-root/path/to/original/directory</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#</span><span 
class="ectt-0800">&#x00A0;Run</span><span 
class="ectt-0800">&#x00A0;my</span><span 
class="ectt-0800">&#x00A0;command</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">./mpirun.cde</span><span 
class="ectt-0800">&#x00A0;-n</span><span 
class="ectt-0800">&#x00A0;2</span><span 
class="ectt-0800">&#x00A0;./my_mpi_linked_executable</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#</span><span 
class="ectt-0800">&#x00A0;Since</span><span 
class="ectt-0800">&#x00A0;HTCondor</span><span 
class="ectt-0800">&#x00A0;will</span><span 
class="ectt-0800">&#x00A0;transfer</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;contents</span><span 
class="ectt-0800">&#x00A0;of</span><span 
class="ectt-0800">&#x00A0;this</span><span 
class="ectt-0800">&#x00A0;directory</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#</span><span 
class="ectt-0800">&#x00A0;back</span><span 
class="ectt-0800">&#x00A0;upon</span><span 
class="ectt-0800">&#x00A0;job</span><span 
class="ectt-0800">&#x00A0;completion.</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#</span><span 
class="ectt-0800">&#x00A0;We</span><span 
class="ectt-0800">&#x00A0;do</span><span 
class="ectt-0800">&#x00A0;not</span><span 
class="ectt-0800">&#x00A0;want</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;.cde</span><span 
class="ectt-0800">&#x00A0;command</span><span 
class="ectt-0800">&#x00A0;and</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;executable</span><span 
class="ectt-0800">&#x00A0;transferred</span><span 
class="ectt-0800">&#x00A0;back.</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">#</span><span 
class="ectt-0800">&#x00A0;To</span><span 
class="ectt-0800">&#x00A0;prevent</span><span 
class="ectt-0800">&#x00A0;the</span><span 
class="ectt-0800">&#x00A0;transfer,</span><span 
class="ectt-0800">&#x00A0;remove</span><span 
class="ectt-0800">&#x00A0;both</span><span 
class="ectt-0800">&#x00A0;files.</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">rm</span><span 
class="ectt-0800">&#x00A0;-f</span><span 
class="ectt-0800">&#x00A0;mpirun.cde</span>
<span 
class="ectt-0800">&#x00A0;</span><br /><span 
class="ectt-0800">rm</span><span 
class="ectt-0800">&#x00A0;-f</span><span 
class="ectt-0800">&#x00A0;my_mpi_linked_executable</span>
</div>
<!--l. 556--><p class="nopar" >
<!--l. 559--><p class="indent" >   Any additional input files that will be needed for the executable that are not already in the tarball should be
included in the list in <span class="textbf">transfer_input_files</span><a 
 id="dx21-74006"></a> command. The corresponding script should then also be updated to
move those files into the directory where the executable will be run.
                                                                                         

                                                                                         
<!--l. 2--><p class="indent" >   <span style="font-size: 200%;"><a 
href="JavaApplications.html" >&#x21D0;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="JavaApplications.html#tailJavaApplications.html" >&#x2199;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="ParallelApplicationsIncludingMPIApplications.html" >&#x2191;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="UsersManual.html#ParallelApplicationsIncludingMPIApplications.html" >&#x21D1;</a></span>&nbsp;<span style="font-size: 200%;"><a 
href="DAGManApplications.html" >&#x21D2;</a></span>&nbsp;<a href="contentsname.html">Contents</a>&nbsp;<a href="indexname.html">Index</a><a 
 id="tailParallelApplicationsIncludingMPIApplications.html"></a>  
</body></html> 
